<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>FORGE-Tree: Diffusion-Forcing Tree Search for Long-Horizon Robot Manipulation</title>
  <meta name="description" content="Project page for FORGE-Tree.">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <style>
    .hero{background:#0E0E10;color:#fff}
    .tagline{opacity:.9}
    .thumb{border-radius:12px}
    .thumb-video{border-radius:12px}
    .thumb-image{width:800px; height:450px; object-fit:contain; border-radius:12px}
    footer{color:#6b7280}
    
    .forge-gradient{
      background: linear-gradient(90deg,
        #A8E6A1 0%,
        #CFEEC2 12%,
        #DDEAFB 28%,
        #E9E4FB 40%,
        #F4D2EE 50%,
        #E9E4FB 60%,
        #DDEAFB 72%,
        #CFEEC2 88%,
        #A8E6A1 100%);
      -webkit-background-clip: text;
              background-clip: text;
      -webkit-text-fill-color: transparent; 
      color: transparent;                 
    }

    /* Â¶ÇÊûúÊîæÂú®Ê∑±Ëâ≤ËÉåÊôØ‰∏äÔºåÁªô‰∏ÄÁÇπÊèèËæπ/Èò¥ÂΩ±Â¢ûÂº∫ÂèØËØªÊÄßÔºàÂèØÈÄâÔºâ */
    .forge-gradient.stroke{
      -webkit-text-stroke: 1px rgba(0,0,0,.18);
              text-stroke: 1px rgba(0,0,0,.18);
      text-shadow: 0 1px 2px rgba(0,0,0,.08);
    }
  </style>
</head>
<body>
  <section class="section">
    <div class="container has-text-centered">
      <h1 class="title is-1 forge-gradient has-text-weight-bold">FORGE-Tree</h1>
      <p class="subtitle is-4 tagline mt-3 has-text-weight-bold">Diffusion-Forcing Tree Search for Long-Horizon Robot Manipulation</p>
      <div class="mt-0">
        <p class="has-text-weight-bold">Yanjia Huang<sup>1*</sup>, Shuo Liu<sup>2*</sup>, Sheng Liu<sup>3</sup>, Qingxiao Xu<sup>1</sup>, Mingyang Wu<sup>1</sup>, Xiangbo Gao<sup>1</sup>, Zhengzhong Tu<sup>1</sup></p>
        <p class="mt-0 has-text-weight-bold">
          <sup>1</sup>Texas A&M University &nbsp;&nbsp;&nbsp; <sup>2</sup>University of Washington &nbsp;&nbsp;&nbsp; <sup>3</sup>Karlsruhe Institute of Technology, Germany<br>
          <small class="has-text-grey has-text-weight-bold"><sup>*</sup>Equal Contributors</small>
      </div>
      <p class="mt-3">
        <a class="button is-link is-light mr-5" href="paper.pdf">Paper</a>
        <a class="button is-link is-light mr-5" href="https://github.com/taco-group/FORGE-Tree">Code</a>
        <a class="button is-link is-light" href="#cite">Cite</a>
      </p>
    </div>
  </section>

  <section class="section">
    <div class="container">
      <div class="has-text-centered">
        <video class="thumb-video" controls poster="cover.png">
          <source src="forge-tree.MP4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      
      <div class="mt-4" style="max-width: 900px; margin: 0 auto;">
        <h3 class="title is-5 mb-3 has-text-centered">Abstract</h3>
        <p class="has-text-justified" style="line-height: 1.6;">
          <em>Long-horizon robot manipulation tasks remain challenging for Vision-Language-Action (VLA) policies due to drift and exposure bias, often denoise the entire trajectory with fixed hyperparameters, causing small geometric errors to compound across stages and offering no mechanism to allocate extra test-time compute where clearances are tight. To address these challenges, we introduce <strong>FORGE-Tree</strong>, a plug-in control layer that couples a stage-aligned <em>Diffusion Forcing</em> (DF) head with test-time <em>Monte Carlo Tree Diffusion</em> (MCTD). With a frozen VLA encoder, DF aligns timesteps to subtask stages; during inference we partially denoise only a target segment while keeping other tokens frozen, turning trajectory refinement into a sequence of local edits. We then apply Monte Carlo Tree Diffusion to select the next segment to refine. A scene graph supplies priors for expansion and geometry relation-aware scoring for rollouts, yielding <em>tree-structured denoising</em> whose performance scales with search budget while preserving the executed prefix. Evaluation on LIBERO, FORGE-Tree improves success rate by <strong>+13.4‚Äì+17.2</strong> pp over the native VLA baselines with both OpenVLA and Octo-Base. Gains remain consistent under comparable compute budgets, especially on long-horizon variants.</em>
        </p>
      </div>
      <h2 class="title is-4 mt-4">Overview</h2>
      <div class="has-text-centered">
        <img class="thumb-image" src="overview.png" alt="FORGE-Tree Pipeline">
        <p class="mt-2 has-text-grey-dark is-italic" style="max-width: 800px; margin: 0 auto;">
          Pretrained VLAs encode the instruction and observations, builds a scene graph <i>ùí¢</i>, our diffusion head predicts noise, the partial-denoising sampler edits a selected future segment with meta-actions <i>a=(k,m,s,w,œÑ)</i>, and MCTD evaluates candidates with geometry-aware rewards before executing the first segment and replanning.
        </p>
      </div>
      <h2 class="title is-4 mt-4">Training & Inference</h2>
      <div class="columns is-centered">
        <div class="column is-two-thirds">
          <div class="has-text-centered">
            <img class="thumb-image" src="DF.png" alt="DF">
          </div>
        </div>
        <div class="column is-one-third">
          <div class="has-text-centered">
            <img class="thumb-image" src="MCTD.png" alt="MCTD">
          </div>
        </div>
      </div>
      <div class="mt-2" style="max-width: 1000px; margin: 0 auto;">
        <p class="has-text-justified" style="line-height: 1.6;">
          <em>Left: <em>Noise as masking</em>‚Äîsubtasks ùíÆ<sub>j</sub> share per-subtask timesteps <i>t[i]=t<sub>j</sub></i> (darker cells indicate larger <i>t</i>). Middle (training): conditioned on <i>c=f<sub>VLA</sub>(o,u)</i>, the diffusion head predicts <i>Œµ<sub>Œ∏</sub>(x<sub>t[i]</sub>,c,t[i])</i>, recovers <i>·∫ã<sub>0</sub>[i]</i>, and is supervised by the DF loss (noise MSE + end-of-trajectory and stage-end geometric terms + smoothness). Right (inference): we <em>partially denoise</em> a selected segment <i>S<sub>k,m</sub></i> using jumpy DDIM with geometry guidance <i>w‚àá<sub>x_t</sub>U(·∫ã<sub>0</sub>;ùí¢)</i>; only the segment evolves while the complement is frozen, and the first segment is committed before replanning.</em>
        </p>
      </div>
      <h2 class="title is-4 mt-4">Experiment Results</h2>
      <div class="has-text-centered">
        <img class="thumb-image" src="Experiments.png" alt="Experiment Results">
      </div>
      <h2 id="cite" class="title is-4 mt-4">BibTeX</h2>
<pre><code>@inproceedings{huang2026forge_tree,
  title={Diffusion-Forcing Tree Search for Long-Horizon Robot Manipulation},
  author={Huang, Yanjia and ...},
  booktitle={ICRA},
  year={2026}
}</code></pre>
    </div>
  </section>

  <footer class="section">
    <div class="container has-text-centered">
      <small>
        Built with Bulma. Code MIT; content CC BY-NC-SA 4.0.
        Adapted from 4K4DGen project page.
      </small>
    </div>
  </footer>
</body>
</html>
